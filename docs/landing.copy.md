# scn-ts – 400-token cheat-sheet your LLM actually reads
*Symbolic Context Notation for TypeScript/JavaScript/CSS and friends*

> “Show me the shape of your repo in 500 tokens or I’m not reading it.”

---

## 1. Why

Large Language Models are starving.
Feed them a whole repo and they drown in semicolons.
Feed them a file list and they hallucinate imports.

- **Context windows are tiny.** 8k tokens disappears fast when you paste `/src`.
- **GPT doesn’t need your `node_modules`.** It needs the graph – what talks to what.
- **You don’t need another IDE.** You need a 1-second command that turns *“here’s my repo”* into *“here’s the 400-token cheat-sheet the model actually reads”*.

scn-ts is a zero-config, WASM-powered static analyzer that spits out **SCN** – a dense, emoji-rich, token-counted summary of every symbol, dependency and cross-file call in your project.
Paste the output straight into GPT/Claude and watch it refactor, review or port your code without ever seeing the source.
---

## 2. What you get (real output)

```bash
$ npx scn-ts "src/**/*.{ts,tsx}" --exclude="**/*.test.ts" --preset=compact
```

```
§1 src/main.tsx
  + ◇ App (1)
  + ~ fetchUsers (2)
    > 2, 3

§2 src/services/api.ts
  ~ getUser (1) ...!
    < 1
    > 3

§3 src/types.ts
  + {} User (1)
    + @ id: #string
    + @ name: #string
```

- **§** file header (id + path)
- **+ / -** exported / private
- **◇ ~ {} ⛶ ¶** class, function, interface, JSX element, CSS rule
- **>** outgoing call / import
- **<** incoming caller
- **... ! o** async, throws, pure
- **#type** inline type signature
- numbers in `()` = unique IDs so the model can disambiguate `User` the interface from `User` the variable.

Token count: **352** for a 12-file mini SaaS – **92 % smaller** than minified source.

---

## 3. Token economics (why this matters)

| representation | tokens | % of 4 k window |
|---|---|---|
| raw source | 18 700 | 467 % ❌ |
| minified | 12 100 | 302 % ❌ |
| AST JSON | 9 400 | 235 % ❌ |
| **SCN compact** | **380** | **9 % ✅** |

You can now fit **ten services** in the same prompt that previously held *half* a service.

---

## 4. Live demo Playground – watch the count melt

[pg.scn.noca.pro](https://pg.scn.noca.pro) – drag-and-drop a folder, move the
“token target” slider, see the map re-shape in real time.

| slider move | tokens saved | architectural loss |
|---|---|---|
| hide private symbols | –35 % | zero |
| drop method bodies | –22 % | zero (signatures stay) |
| filter `*.test.ts` | –18 % | zero |
| collapse React props | –15 % | zero |
| **total** | **~ 70 %** | **none** |

---

## 5. CLI quick start

```bash
# global install
npm i -g scn-ts            # or yarn/pnpm/bun

# basic
scn-ts "src/**/*.{ts,tsx}" --output map.scn

# monorepo
scn-ts "apps/*/src/**/*" --exclude="**/*.stories.tsx" --max-workers=8

# watch mode
scn-ts "src/**/*" --watch --preset=minimal
```

All flags:

| flag | default | meaning |
|---|---|---|
| `--output, -o` | stdout | write to file |
| `--project, -p` | auto | path to tsconfig.json |
| `--preset` | default | minimal / compact / default / detailed / verbose |
| `--exclude` | [] | glob array |
| `--include` | [] | glob array (if omitted uses positional) |
| `--max-workers` | 1 | parallel parsers |
| `--watch` | false | re-gen on change |
| `--token-limit` | none | auto-tune preset to hit token budget |

---

## 6. Configuration file (check in to repo)

`scn.config.js`
```js
export default {
  include: ['src/**/*.{ts,tsx}'],
  exclude: ['**/*.test.ts', '**/generated/**'],
  preset: 'compact',
  output: 'scn.map',
  maxWorkers: 4,
  // you can still override via CLI
};
```

---

## 7. Programmatic API (Node / Bun)

```ts
import { generateScn } from 'scn-ts';

// file-system mode
const scn = await generateScn({
  include: ['src/**/*.ts'],
  exclude: ['**/*.spec.ts'],
  preset: 'compact'
});

// in-memory (browser or server)
const scn = await generateScn({
  files: [
    { path: 'main.ts', content: 'export const pi = 3.14' }
  ]
});
```

Return value is a plain string – send it to OpenAI, Anthropic, or your self-hosted model.

---

## 8. Browser / Edge-runtime usage

1. Copy WASM parsers once
   ```bash
   npx scn-ts copy-wasm ./public/wasm
   ```

2. Load & run (zero bundler config needed)
   ```html
   <script type="module">
     import { initializeParser, generateScn } from 'https://unpkg.com/scn-ts?module';
     await initializeParser({ wasmBaseUrl: '/wasm/' });

     const files = await getFilesFromDropzone(); // your UI
     const map  = generateScn({ files });
     prompt.value = map;          // 400 tokens
   </script>
   ```

Works in Chrome, Firefox, Safari, Node 18+, Deno, Bun, Vercel Edge, Cloudflare Workers.

---

## 9. SCN Specification (mini-RFC)

**Grammar (EBNF):**
```
file       ::= "§" fileId path [directive] LF topLevel+
topLevel   ::= indent (symbol | depLine) LF
symbol     ::= visibility icon id name [sig] [meta]
depLine    ::= ">" | "<" idList
visibility ::= "+" | "-"
icon       ::= "◇" | "~" | "@" | "{}" | "⛶" | "¶" | "☰" | "=:"
meta       ::= "..." | "!" | "o" | "[label]"
idList     ::= id *("," id)
```

**Unicode icons (stable, never change):**
| icon | meaning |
|---|---|
| `◇` | container (class, struct, component) |
| `~` | callable (function, method) |
| `@` | value (variable, property, constant) |
| `{}` | interface / trait |
| `☰` | enum |
| `=:` | type alias |
| `⛶` | JSX/HTML element |
| `¶` | CSS selector |

IDs are hierarchical: `(fileId.symbolId)` so GPT can follow edges without name clashes.

---

## 10. Language matrix (today)

| language | parser | symbols | deps | notes |
|---|---|---|---|---|
| TypeScript | ✅ | ◇ ~ @ {} ☰ =: | -> <- | full |
| TSX / JSX | ✅ | ◇ ~ @ ⛶ | -> <- | styled-components tag extracted |
| JavaScript | ✅ | ◇ ~ @ | -> <- | ES-module & CommonJS |
| CSS | ✅ | ¶ | -> <- | intents: 📐 ✍ 💧 |
| Go | ✅ | ◇ ~ | -> <- | goroutines tagged |
| Rust | ✅ | ◇ {} +impl | -> <- | traits & macros |
| Python | 🚧 | | | query WIP |
| Java | 🚧 | | | query WIP |

Adding a language = write 30-line tree-sitter query + 5-line icon map.
PRs welcome.

---

## 11. Token-impact API (advanced)

Ask “how many tokens will I save if I hide private methods?”
`scn-ts` re-serialises the graph twice and returns the delta:

```ts
const impact = calculateTokenImpact(analysedFiles, {
  showPrivateIndicator: false
});
console.log(impact.options.showPrivateIndicator); // -142
```

Use it to build **adaptive context** – keep shrinking until you fit the budget.

---

## 12. Performance (hypothetical)

Cold run (M1, 8 cores, 2 k files):

| stage | time |
|---|---|
| WASM init | 110 ms |
| parse + analyse | 480 ms |
| serialise (compact) | 25 ms |
| **total** | **< 0.6 s** |

Incremental watch mode: < 30 ms for a single-file change (tree-sitter incremental parse).

Memory: ~ 1.2 × source size during analysis, then GC’d.

---

## 13. Design decisions

- **tree-sitter** – incremental, error-tolerant, multi-language.
- **WASM** – same binary runs in browser, edge, or server.
- **No bundler magic** – ES modules only, `?module` CDN link works.
- **No AST dump** – we throw away *statements* and keep *symbols + edges*.
- **Topological sort** – GPT sees bottom-up dependencies, reduces hallucination.
- **Stable icon set** – single Unicode char, never本地化, token-efficient.
- **Hierarchical IDs** – lets model reason about “file 3 symbol 2” without names.
- **Preset system** – hard-coded filters so you don’t need a YAML engine.

---

## 14. Common use-cases

| scenario | paste this into prompt |
|---|---|
| refactor epic | SCN + “move auth logic to new package” |
| code review | SCN + “any circular deps?” |
| add feature | SCN + “add Stripe webhook handler following same pattern” |
| migration | SCN + “convert from Express to Fastify” |
| on-boarding | SCN + “explain data flow” |

---

## 15. FAQ

**Q: Does GPT really understand the icons?**
A: Yes. They are single Unicode chars and appear thousands of times in training data (Unicode chess, cards, etc.). We prompt-engineered once and never looked back.

**Q: Why not just `ctags` + `grep`?**
A: ctags is per-file, no cross-file edges, no token counting, no browser.

**Q: Will you break when TS 5.7 adds new syntax?**
A: Only if tree-sitter grammar breaks – usually fixed upstream within days. Our queries are tiny, easy to patch.

**Q: Proprietary code?**
A: Everything runs locally. WASM is loaded from your domain; no telemetry, no cloud.

---

## 16. Contributing

- Add a language: edit `/src/queries/yourlang.ts` + 5-line icon map.
- Improve heuristics (pure fn detection, React hooks, etc.).
- Speed: we have a `noop` parser benchmark – beat it.
- Docs: every PR that changes output must update *this* readme example.

Repo: [github.com/nocapro/scn-ts](https://github.com/nocapro/scn-ts)
Issues & feature requests welcome.

---

## 17. License

MIT © 2025 scn-ts contributors – built during the context-window crunch weeks.
Star if you hate pasting 3k lines into ChatGPT.

___

> SCN is the shared engine behind **www.noca.pro** – a zero-friction, Visual Context Engineering with AI-native patch engine that turns your clipboard into a surgical code-editing laser.
